// Task aggregation â€” sync from GitHub issues and watch paths

import { existsSync, readFileSync, writeFileSync, mkdirSync, readdirSync, appendFileSync } from "fs";
import { join, dirname } from "path";
import { loadConfigSync, harnessDir, priorityProjects, preemptAutonomy, slotsCount } from "../config.ts";
import { slotsFilePath } from "../config.ts";
import { parseSlotBlocks, getProcess, getTask } from "../slots/markdown.ts";
import { writeTaskFile, updateFrontmatterField, addFrontmatterField, parseTaskFrontmatter } from "./markdown.ts";

function yamlEscape(value: string): string {
  return value.replace(/\\/g, "\\\\").replace(/"/g, '\\"');
}

function contentFingerprint(text: string): string {
  const normalized = text
    .toLowerCase()
    .replace(/[^a-z0-9 ]/g, "")
    .replace(/\s+/g, " ")
    .trim();

  // Use Bun's built-in hasher
  const hasher = new Bun.CryptoHasher("md5");
  hasher.update(normalized);
  return hasher.digest("hex").slice(0, 8);
}

function sanitizePathForId(path: string): string {
  const home = process.env.HOME ?? "";
  let p = path;
  if (p.startsWith(home + "/")) p = p.slice(home.length + 1);
  if (p.startsWith("~/")) p = p.slice(2);
  return p.replace(/[/. ]/g, "-").replace(/[^a-zA-Z0-9_-]/g, "");
}

interface GhIssue {
  number: number;
  title: string;
  url: string;
  labels: { name: string }[];
}

interface GhIssueState extends GhIssue {
  state: string;
  stateReason?: string | null;
  closedAt?: string | null;
  updatedAt?: string | null;
}

async function fetchGitHubIssues(repo: string): Promise<GhIssue[]> {
  const result = Bun.spawnSync(
    ["gh", "issue", "list", "-R", repo, "--state", "open", "--limit", "200", "--json", "number,title,url,labels"],
    { stdout: "pipe", stderr: "pipe" },
  );
  if (result.exitCode !== 0) {
    console.error(`ludics: failed to fetch issues from ${repo}: ${result.stderr.toString().trim()}`);
    return [];
  }
  try {
    return JSON.parse(result.stdout.toString()) as GhIssue[];
  } catch {
    return [];
  }
}

export async function tasksSync(): Promise<void> {
  const config = loadConfigSync();
  const harness = harnessDir();
  const yamlFile = join(harness, "tasks.yaml");
  const tasksDir = join(harness, "tasks");

  const timestamp = new Date().toISOString().replace(/\.\d{3}Z$/, "Z");
  const lines: string[] = [
    "# Generated by ludics",
    `generated_at: "${timestamp}"`,
    "tasks:",
  ];

  // GitHub issues from projects config
  if (config.projects) {
    for (const project of config.projects) {
      if (!project.issues) continue;
      const issues = await fetchGitHubIssues(project.repo);
      const repoName = project.repo.split("/").pop()!;

      for (const issue of issues) {
        const id = `gh-${repoName}-${issue.number}`;
        const escapedTitle = yamlEscape(issue.title);
        const labelsStr = issue.labels.map((l) => l.name).join(",");
        lines.push(`  - id: ${id}`);
        lines.push(`    title: "${escapedTitle}"`);
        lines.push(`    source: github`);
        lines.push(`    repo: ${project.repo}`);
        lines.push(`    url: ${issue.url}`);
        lines.push(`    labels: "${yamlEscape(labelsStr)}"`);
      }
    }
  }

  // TODO: watch paths from triggers config (deferred to Phase 4 with triggers)

  writeFileSync(yamlFile, lines.join("\n") + "\n");
  console.log(`Wrote tasks to ${yamlFile}`);

  // Auto-convert to individual task files
  await tasksConvert();

  // Refresh metadata and closed/open state for existing GitHub-backed task files
  await tasksUpdate();

  // Queue elaboration for new ready tasks
  tasksQueueElaborations();

  // Queue preemptions for priority project tasks
  tasksQueuePreemptions();
}

export async function tasksConvert(): Promise<void> {
  const harness = harnessDir();
  const yamlFile = join(harness, "tasks.yaml");
  const tasksDir = join(harness, "tasks");

  if (!existsSync(yamlFile)) {
    throw new Error("tasks.yaml not found (run: ludics tasks sync first)");
  }

  mkdirSync(tasksDir, { recursive: true });
  const today = new Date().toISOString().slice(0, 10);

  const content = readFileSync(yamlFile, "utf-8");
  const lines = content.split("\n");

  let count = 0;
  let currentId = "";
  let currentTitle = "";
  let currentSource = "";
  let currentUsesBrowser = false;
  let currentRepo = "";
  let currentUrl = "";
  let currentLabels = "";
  let currentPath = "";

  function flushCurrent(): void {
    if (!currentId) return;
    const created = writeTaskFile(
      tasksDir, currentId, currentTitle, currentSource,
      currentUsesBrowser,
      currentRepo, currentUrl, currentLabels, today, currentPath || undefined,
    );
    if (created) count++;
  }

  for (const line of lines) {
    let m: RegExpMatchArray | null;

    m = line.match(/^\s*-\s*id:\s*(.+)$/);
    if (m) {
      flushCurrent();
      currentId = m[1]!.replace(/"/g, "");
      currentTitle = "";
      currentSource = "";
      currentUsesBrowser = false;
      currentRepo = "";
      currentUrl = "";
      currentLabels = "";
      currentPath = "";
      continue;
    }

    m = line.match(/^\s*title:\s*"?(.+?)"?\s*$/);
    if (m) { currentTitle = m[1]!.replace(/"$/, ""); continue; }

    m = line.match(/^\s*source:\s*(.+)$/);
    if (m) { currentSource = m[1]!; continue; }

    m = line.match(/^\s*uses_browser:\s*(.+)$/);
    if (m) {
      const v = m[1]!.trim().toLowerCase();
      currentUsesBrowser = v === "true" || v === "1" || v === "yes";
      continue;
    }

    m = line.match(/^\s*repo:\s*(.+)$/);
    if (m) { currentRepo = m[1]!; continue; }

    m = line.match(/^\s*url:\s*(.+)$/);
    if (m) { currentUrl = m[1]!; continue; }

    m = line.match(/^\s*labels:\s*"?(.*?)"?\s*$/);
    if (m) { currentLabels = m[1]!.replace(/"$/, ""); continue; }

    m = line.match(/^\s*path:\s*"?(.+?)"?\s*$/);
    if (m) { currentPath = m[1]!.replace(/"$/, ""); continue; }
  }

  flushCurrent();
  console.log(`Created ${count} task files in ${tasksDir}`);
}

function escapeRegExp(value: string): string {
  return value.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
}

function formatYamlScalar(value: string | number | boolean | null): string {
  if (value === null) return "null";
  if (typeof value === "boolean") return value ? "true" : "false";
  if (typeof value === "number") return String(value);
  return `"${yamlEscape(value)}"`;
}

function setFrontmatterScalar(filePath: string, field: string, value: string | number | boolean | null): boolean {
  const content = readFileSync(filePath, "utf-8");
  const rendered = formatYamlScalar(value);
  const desiredLine = `${field}: ${rendered}`;
  const pattern = new RegExp(`^${escapeRegExp(field)}:\\s*.*$`, "m");
  const existingLine = content.match(pattern)?.[0];
  if (existingLine === desiredLine) return false;
  if (existingLine) {
    updateFrontmatterField(filePath, field, rendered);
  } else {
    addFrontmatterField(filePath, field, rendered);
  }
  return true;
}

function parseRepoFromGitHubUrl(url: string | undefined): string | null {
  if (!url) return null;
  try {
    const parsed = new URL(url);
    if (parsed.hostname !== "github.com") return null;
    const parts = parsed.pathname.split("/").filter(Boolean);
    if (parts.length < 2) return null;
    return `${parts[0]}/${parts[1]}`;
  } catch {
    return null;
  }
}

function normalizeState(value: string | null | undefined): string {
  return String(value ?? "").trim().toLowerCase();
}

function normalizeStateReason(value: string | null | undefined): string {
  return normalizeState(value).replace(/-/g, "_");
}

function closedStatusFromIssue(issue: GhIssueState): "done" | "abandoned" | null {
  const state = normalizeState(issue.state);
  if (state !== "closed") return null;
  const reason = normalizeStateReason(issue.stateReason);
  if (reason === "not_planned") return "abandoned";
  return "done";
}

function parseIssueNumberFromTaskId(taskId: string): number | null {
  const m = taskId.match(/-(\d+)$/);
  if (!m) return null;
  const n = Number(m[1]);
  return Number.isFinite(n) ? n : null;
}

function fetchGitHubIssuesAll(repo: string): Map<number, GhIssueState> {
  const result = Bun.spawnSync(
    [
      "gh", "issue", "list",
      "-R", repo,
      "--state", "all",
      "--limit", "1000",
      "--json", "number,title,url,labels,state,stateReason,closedAt,updatedAt",
    ],
    { stdout: "pipe", stderr: "pipe" },
  );

  if (result.exitCode !== 0) {
    console.error(`ludics: failed to fetch issue metadata from ${repo}: ${result.stderr.toString().trim()}`);
    return new Map<number, GhIssueState>();
  }

  let issues: GhIssueState[] = [];
  try {
    issues = JSON.parse(result.stdout.toString()) as GhIssueState[];
  } catch {
    console.error(`ludics: failed to parse issue metadata from ${repo}`);
    return new Map<number, GhIssueState>();
  }

  if (issues.length >= 1000) {
    console.error(`ludics: warning: ${repo} returned 1000 issues; results may be truncated`);
  }

  const map = new Map<number, GhIssueState>();
  for (const issue of issues) {
    map.set(issue.number, issue);
  }
  return map;
}

interface LocalTaskRecord {
  id: string;
  filePath: string;
  source: string;
  title: string;
  githubTitle?: string;
  status: string;
  url?: string;
  project: string;
  githubIssue?: number;
  mergedInto?: string;
  mergedFrom: string[];
  neighbors: Set<string>;
}

function buildDuplicateComponents(records: Map<string, LocalTaskRecord>): {
  componentByTask: Map<string, string>;
  membersByComponent: Map<string, string[]>;
} {
  const componentByTask = new Map<string, string>();
  const membersByComponent = new Map<string, string[]>();

  for (const startId of records.keys()) {
    if (componentByTask.has(startId)) continue;
    const stack = [startId];
    const members: string[] = [];
    componentByTask.set(startId, startId);

    while (stack.length > 0) {
      const current = stack.pop()!;
      members.push(current);
      const rec = records.get(current);
      if (!rec) continue;
      for (const next of rec.neighbors) {
        if (!records.has(next)) continue;
        if (componentByTask.has(next)) continue;
        componentByTask.set(next, startId);
        stack.push(next);
      }
    }

    membersByComponent.set(startId, members);
  }

  return { componentByTask, membersByComponent };
}

function inferRepoForTask(
  record: LocalTaskRecord,
  reposBySlug: Map<string, string[]>,
): string | null {
  const parsed = parseRepoFromGitHubUrl(record.url);
  if (parsed) return parsed;
  if (!record.project) return null;
  const candidates = reposBySlug.get(record.project) ?? [];
  if (candidates.length === 1) return candidates[0]!;
  return null;
}

function inferIssueNumber(record: LocalTaskRecord): number | null {
  if (typeof record.githubIssue === "number" && Number.isFinite(record.githubIssue)) {
    return record.githubIssue;
  }
  return parseIssueNumberFromTaskId(record.id);
}

function latestIso(values: Array<string | null | undefined>): string | null {
  let latest: string | null = null;
  for (const value of values) {
    if (!value) continue;
    if (!latest || value > latest) latest = value;
  }
  return latest;
}

export async function tasksUpdate(): Promise<void> {
  const harness = harnessDir();
  const tasksDir = join(harness, "tasks");
  if (!existsSync(tasksDir)) {
    throw new Error(`tasks directory not found: ${tasksDir} (run: ludics tasks sync)`);
  }

  const files = readdirSync(tasksDir).filter((f: string) => f.endsWith(".md"));
  const records = new Map<string, LocalTaskRecord>();
  for (const file of files) {
    const filePath = join(tasksDir, file);
    const content = readFileSync(filePath, "utf-8");
    let fm;
    try {
      fm = parseTaskFrontmatter(content);
    } catch {
      continue;
    }
    if (!fm.id) continue;
    records.set(fm.id, {
      id: fm.id,
      filePath,
      source: String(fm.source ?? ""),
      title: String(fm.title ?? ""),
      githubTitle: fm.github_title,
      status: String(fm.status ?? "ready"),
      url: fm.url,
      project: String(fm.project ?? ""),
      githubIssue: fm.github_issue,
      mergedInto: fm.merged_into,
      mergedFrom: fm.merged_from ?? [],
      neighbors: new Set<string>(),
    });
  }

  for (const rec of records.values()) {
    if (rec.mergedInto && records.has(rec.mergedInto)) {
      rec.neighbors.add(rec.mergedInto);
      records.get(rec.mergedInto)!.neighbors.add(rec.id);
    }
    for (const linkedId of rec.mergedFrom) {
      if (!records.has(linkedId)) continue;
      rec.neighbors.add(linkedId);
      records.get(linkedId)!.neighbors.add(rec.id);
    }
  }

  const githubRecords = Array.from(records.values()).filter((rec) => rec.source === "github" || rec.id.startsWith("gh-"));
  if (githubRecords.length === 0) {
    console.log("No GitHub-backed task files found");
    return;
  }

  const config = loadConfigSync();
  const reposBySlug = new Map<string, string[]>();
  for (const project of (config.projects ?? [])) {
    const slug = project.repo.split("/").pop() ?? "";
    if (!slug) continue;
    const existing = reposBySlug.get(slug) ?? [];
    existing.push(project.repo);
    reposBySlug.set(slug, existing);
  }

  const issueNumbersByRepo = new Map<string, Set<number>>();
  let unresolvedRepo = 0;
  let unresolvedIssue = 0;
  for (const rec of githubRecords) {
    const repo = inferRepoForTask(rec, reposBySlug);
    if (!repo) {
      unresolvedRepo++;
      console.error(`ludics: could not infer repo for ${rec.id}; skipping`);
      continue;
    }
    const issueNumber = inferIssueNumber(rec);
    if (!issueNumber) {
      unresolvedIssue++;
      console.error(`ludics: could not infer issue number for ${rec.id}; skipping`);
      continue;
    }
    const bucket = issueNumbersByRepo.get(repo) ?? new Set<number>();
    bucket.add(issueNumber);
    issueNumbersByRepo.set(repo, bucket);
  }

  const issuesByRepo = new Map<string, Map<number, GhIssueState>>();
  for (const repo of issueNumbersByRepo.keys()) {
    issuesByRepo.set(repo, fetchGitHubIssuesAll(repo));
  }

  const { componentByTask, membersByComponent } = buildDuplicateComponents(records);
  const closureIntents = new Map<string, Array<{ status: "done" | "abandoned"; closedAt: string | null }>>();

  let metadataUpdates = 0;
  let stateClosures = 0;
  let titleSynced = 0;
  let titlePreserved = 0;
  let matchedIssues = 0;
  let missingOnGitHub = 0;
  const touchedTasks = new Set<string>();

  for (const rec of githubRecords) {
    const repo = inferRepoForTask(rec, reposBySlug);
    const issueNumber = inferIssueNumber(rec);
    if (!repo || !issueNumber) continue;

    const issue = issuesByRepo.get(repo)?.get(issueNumber);
    if (!issue) {
      missingOnGitHub++;
      console.error(`ludics: issue not found in ${repo}: #${issueNumber} (${rec.id})`);
      continue;
    }
    matchedIssues++;

    const labelsCsv = issue.labels.map((label) => label.name).join(",");
    const state = normalizeState(issue.state);
    const stateReason = normalizeStateReason(issue.stateReason);

    const previousRemoteTitle = rec.githubTitle;
    const localTitle = rec.title;
    const remoteTitle = issue.title;
    const canAutoSyncTitle =
      typeof previousRemoteTitle === "string" &&
      localTitle === previousRemoteTitle;

    let titleChanged = false;
    if (canAutoSyncTitle) {
      titleChanged = setFrontmatterScalar(rec.filePath, "title", remoteTitle);
      if (titleChanged) {
        titleSynced++;
        touchedTasks.add(rec.id);
      }
    } else if (localTitle !== remoteTitle) {
      // Local title diverged from remote snapshot; preserve local intent.
      titlePreserved++;
    }

    const updates = [
      setFrontmatterScalar(rec.filePath, "github_title", remoteTitle),
      setFrontmatterScalar(rec.filePath, "url", issue.url),
      setFrontmatterScalar(rec.filePath, "github_repo", repo),
      setFrontmatterScalar(rec.filePath, "github_issue", issue.number),
      setFrontmatterScalar(rec.filePath, "github_labels", labelsCsv),
      setFrontmatterScalar(rec.filePath, "github_state", state || "open"),
      setFrontmatterScalar(rec.filePath, "github_state_reason", stateReason || null),
      setFrontmatterScalar(rec.filePath, "github_updated_at", issue.updatedAt ?? null),
      setFrontmatterScalar(rec.filePath, "github_closed_at", issue.closedAt ?? null),
    ];

    const metadataChanged = updates.filter(Boolean).length;
    if (metadataChanged > 0) {
      metadataUpdates += metadataChanged;
      touchedTasks.add(rec.id);
    }

    const closedStatus = closedStatusFromIssue(issue);
    if (!closedStatus) continue;
    const componentId = componentByTask.get(rec.id) ?? rec.id;
    const intents = closureIntents.get(componentId) ?? [];
    intents.push({ status: closedStatus, closedAt: issue.closedAt ?? null });
    closureIntents.set(componentId, intents);
  }

  for (const [componentId, intents] of closureIntents.entries()) {
    const closureStatus: "done" | "abandoned" = intents.some((item) => item.status === "abandoned")
      ? "abandoned"
      : "done";
    const completedAt = latestIso(intents.map((item) => item.closedAt))
      ?? new Date().toISOString().replace(/\.\d{3}Z$/, "Z");
    const members = membersByComponent.get(componentId) ?? [componentId];

    for (const taskId of members) {
      const rec = records.get(taskId);
      if (!rec) continue;
      if (rec.status === "merged") continue;

      let changed = false;
      if (!["done", "abandoned"].includes(rec.status)) {
        if (setFrontmatterScalar(rec.filePath, "status", closureStatus)) {
          stateClosures++;
          changed = true;
        }
      }
      if (setFrontmatterScalar(rec.filePath, "completed", completedAt)) {
        changed = true;
      }
      if (changed) touchedTasks.add(taskId);
    }
  }

  console.log(
    `Updated ${touchedTasks.size} task(s): ${metadataUpdates} metadata field change(s), ${titleSynced} title sync(s), ${stateClosures} closed-state status change(s)`,
  );
  console.log(
    `Preserved ${titlePreserved} local title override(s)`,
  );
  console.log(
    `Matched ${matchedIssues}/${githubRecords.length} GitHub-backed task(s); unresolved repo=${unresolvedRepo}, unresolved issue=${unresolvedIssue}, missing on GitHub=${missingOnGitHub}`,
  );
}

function tasksQueueElaborations(): void {
  const harness = harnessDir();
  const tasksDir = join(harness, "tasks");
  if (!existsSync(tasksDir)) return;

  const queueFile = join(harness, "mag", "queue.jsonl");
  let alreadyQueued = "";
  if (existsSync(queueFile)) {
    const content = readFileSync(queueFile, "utf-8");
    alreadyQueued = content.split("\n").filter((l) => l.includes('"action":"elaborate"')).join("\n");
  }

  const needsElab = tasksNeedsElaborationList(tasksDir);
  let count = 0;

  for (const taskId of needsElab) {
    const file = join(tasksDir, `${taskId}.md`);
    if (!existsSync(file)) continue;

    const content = readFileSync(file, "utf-8");
    const statusMatch = content.match(/^status:\s*(.+)$/m);
    if (statusMatch && statusMatch[1]!.trim() !== "ready") continue;

    if (alreadyQueued.includes(`"task":"${taskId}"`)) continue;

    mkdirSync(dirname(queueFile), { recursive: true });
    const timestamp = new Date().toISOString().replace(/\.\d{3}Z$/, "Z");
    const requestId = `req-${Math.floor(Date.now() / 1000)}-${process.pid}`;
    const request = `{"id":"${requestId}","action":"elaborate","timestamp":"${timestamp}","task":"${taskId}"}`;
    appendFileSync(queueFile, request + "\n");
    count++;
  }

  if (count > 0) {
    console.error(`ludics: Queued ${count} task(s) for elaboration`);
  }
}

function tasksNeedsElaborationList(tasksDir: string): string[] {
  const files = readdirSync(tasksDir).filter((f: string) => f.endsWith(".md"));
  const result: string[] = [];

  for (const f of files) {
    const content = readFileSync(join(tasksDir, f), "utf-8");
    const idMatch = content.match(/^id:\s*(.+)$/m);
    if (!idMatch) continue;
    const id = idMatch[1]!.trim();

    const statusMatch = content.match(/^status:\s*(.+)$/m);
    const status = statusMatch ? statusMatch[1]!.trim() : "";
    if (["merged", "done", "abandoned"].includes(status)) continue;

    let needsElab = false;
    if (!content.includes("\nelaborated:")) needsElab = true;
    if (content.includes("- [ ] TBD\n")) needsElab = true;

    if (needsElab) result.push(id);
  }

  return result;
}

function tasksQueuePreemptions(): void {
  const priProjects = priorityProjects();
  if (priProjects.length === 0) return;

  const harness = harnessDir();
  const tasksDir = join(harness, "tasks");
  if (!existsSync(tasksDir)) return;

  // Check if all slots are occupied (otherwise normal flow ready path suffices)
  const slotsFile = slotsFilePath(harness);
  if (!existsSync(slotsFile)) return;
  const slotsContent = readFileSync(slotsFile, "utf-8");
  const blocks = parseSlotBlocks(slotsContent);
  const count = slotsCount();
  let hasEmpty = false;
  for (let i = 1; i <= count; i++) {
    const block = blocks.get(i);
    const process = block ? getProcess(block).trim() : "(empty)";
    if (!process || process === "(empty)") { hasEmpty = true; break; }
  }
  if (hasEmpty) return; // empty slot available, no need to preempt

  const queueFile = join(harness, "mag", "queue.jsonl");
  let alreadyQueued = "";
  if (existsSync(queueFile)) {
    alreadyQueued = readFileSync(queueFile, "utf-8");
  }

  // Collect projects that already have a task in-flight (in-progress or preempted in a slot)
  // to avoid thrashing with multiple preemptions for the same project
  const projectsInFlight = new Set<string>();
  for (let i = 1; i <= count; i++) {
    const block = blocks.get(i);
    if (!block) continue;
    const slotTaskId = getTask(block).trim();
    if (!slotTaskId || slotTaskId === "null") continue;
    const taskFile = join(tasksDir, `${slotTaskId}.md`);
    if (!existsSync(taskFile)) continue;
    const taskContent = readFileSync(taskFile, "utf-8");
    const pm = taskContent.match(/^project:\s*(.+)$/m);
    if (pm && priProjects.includes(pm[1]!.trim())) {
      projectsInFlight.add(pm[1]!.trim());
    }
  }

  // Also count projects already queued for preemption
  const queuedLines = alreadyQueued.split("\n").filter((l) => l.includes('"action":"preempt"'));
  for (const line of queuedLines) {
    try {
      const req = JSON.parse(line) as Record<string, unknown>;
      const qTask = String(req.task ?? "");
      if (!qTask) continue;
      const taskFile = join(tasksDir, `${qTask}.md`);
      if (!existsSync(taskFile)) continue;
      const taskContent = readFileSync(taskFile, "utf-8");
      const pm = taskContent.match(/^project:\s*(.+)$/m);
      if (pm && priProjects.includes(pm[1]!.trim())) {
        projectsInFlight.add(pm[1]!.trim());
      }
    } catch { /* skip */ }
  }

  const files = readdirSync(tasksDir).filter((f: string) => f.endsWith(".md"));
  let queued = 0;

  for (const f of files) {
    const content = readFileSync(join(tasksDir, f), "utf-8");
    const idMatch = content.match(/^id:\s*(.+)$/m);
    if (!idMatch) continue;
    const id = idMatch[1]!.trim();

    const statusMatch = content.match(/^status:\s*(.+)$/m);
    if (!statusMatch || statusMatch[1]!.trim() !== "ready") continue;

    const projectMatch = content.match(/^project:\s*(.+)$/m);
    if (!projectMatch) continue;
    const project = projectMatch[1]!.trim();

    if (!priProjects.includes(project)) continue;
    if (projectsInFlight.has(project)) continue; // one preemption per project at a time
    // Check per-line that this exact task already has a preempt entry queued
    const alreadyQueuedForTask = alreadyQueued.split("\n").some(
      (line) => line.includes(`"task":"${id}"`) && line.includes('"action":"preempt"'),
    );
    if (alreadyQueuedForTask) continue;

    mkdirSync(dirname(queueFile), { recursive: true });
    const timestamp = new Date().toISOString().replace(/\.\d{3}Z$/, "Z");
    const requestId = `req-${Math.floor(Date.now() / 1000)}-${process.pid}`;
    const autonomy = preemptAutonomy();
    const request = `{"id":"${requestId}","action":"preempt","timestamp":"${timestamp}","task":"${id}","autonomy":"${autonomy}"}`;
    appendFileSync(queueFile, request + "\n");
    // Mark task immediately so subsequent syncs won't re-queue it
    // (closes the race window between queue-pop and actual slot assignment)
    updateFrontmatterField(join(tasksDir, f), "status", "preempt-queued");
    projectsInFlight.add(project); // prevent queuing another from same project in this pass
    queued++;
  }

  if (queued > 0) {
    console.error(`ludics: Queued ${queued} priority task(s) for preemption`);
  }
}

export { tasksNeedsElaborationList, tasksQueueElaborations, tasksQueuePreemptions, contentFingerprint };
